{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keypoint_matching.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4Q9BS7eYp9Z"
      },
      "source": [
        "# CMPT 732 - Fall 2021\n",
        "# Keypoint detection, matching, and RANSAC\n",
        "\n",
        "__content creator:__ Aryan Mikaeili"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p11RVJjAcSlC"
      },
      "source": [
        "!pip install opencv-python==4.5.4.58"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3f4XY2IV9Ln"
      },
      "source": [
        "#import modules\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKWkfdV8YxrD"
      },
      "source": [
        "#Practice 1: Difference of Gaussians\n",
        "\n",
        "1. read image beaver.png\n",
        "2. apply gaussian kernel using the function cv2.GaussianBlur() with 5 $\\times$ 5 kernel and and two scales of 2 and 4\n",
        "3. show the difference of Gaussian\n",
        "4. repeat the process with different scales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9qhljdIZLdU"
      },
      "source": [
        "#read image\n",
        "\n",
        "image = ...\n",
        "\n",
        "#apply Gaussian kernel\n",
        "\n",
        "image1 = ...\n",
        "image2 = ...\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "RHhlT3U2WBwO"
      },
      "source": [
        "#@title Solution\n",
        "\n",
        "#read image\n",
        "image = cv2.imread('images/beaver.png', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "#apply Gaussian kernel\n",
        "image1 = cv2.GaussianBlur(image, (5, 5), 2)\n",
        "image2 = cv2.GaussianBlur(image, (5,5), 4)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "xZzVCnyqWhBW"
      },
      "source": [
        "#@title Run this cell to see results\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize = (15, 15))\n",
        "\n",
        "axes[0].imshow(image, cmap = 'gray')\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title('Original image')\n",
        "\n",
        "axes[1].imshow(image1, cmap = 'gray')\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title('first filtered image')\n",
        "\n",
        "axes[2].imshow(image2, cmap = 'gray')\n",
        "axes[2].axis('off')\n",
        "axes[2].set_title('second filtered image')\n",
        "\n",
        "axes[3].imshow(image2 - image1, cmap = 'gray')\n",
        "axes[3].axis('off')\n",
        "axes[3].set_title('difference of gaussians')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnXNuZ38aEbc"
      },
      "source": [
        "#Practice 2: Sift feature detector\n",
        "\n",
        "1. read an image (you can use the beaver that you loaded at the previous practice)\n",
        "2. create a Sift feature detector using cv2.SIFT_create()\n",
        "3.detect keypoints using the function detect(image, section). if your sift object is named s you should write s.detect().\n",
        "4. draw the keypoints using cv2.drawKeypoints(image, keypoints, section)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9gvGS-xafQF"
      },
      "source": [
        "#create sift object\n",
        "sift_detector = ...\n",
        "\n",
        "#detect keypoints\n",
        "keypoints = ...\n",
        "\n",
        "#draw keypoints\n",
        "\n",
        "image_keys = ...\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jA-fO7cYdUHF"
      },
      "source": [
        "#@title Solution\n",
        "\n",
        "sift_detector = cv2.SIFT_create()\n",
        "\n",
        "keypoints = sift_detector.detect(image, None)\n",
        "\n",
        "image_keys = cv2.drawKeypoints(image, keypoints, None)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "LD_aqkNUbW-0"
      },
      "source": [
        "#@title Run this cell to see results\n",
        "\n",
        "plt.imshow(image_keys, cmap = 'gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywJ1UayEfUbR"
      },
      "source": [
        "#draw rich keypoints\n",
        "\n",
        "image_keys_rich = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "plt.imshow(image_keys_rich, cmap = 'gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryMCJ7pxf0hB"
      },
      "source": [
        "print(type(keypoints))\n",
        "print(len(keypoints))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd753P2bf7cV"
      },
      "source": [
        "kp = keypoints[0]\n",
        "\n",
        "print(type(kp))\n",
        "print(dir(kp))\n",
        "\n",
        "print('angle', kp.angle)\n",
        "print('octave', kp.octave)\n",
        "print('scale', kp.size)\n",
        "print('location', kp.pt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "248SzIGPgxjL"
      },
      "source": [
        "#Practice 3: Descriptor extraction\n",
        "\n",
        "1. on the keypoints extracted in the previous practice run compute(image, keypoints) to extract descriptors for each keypoints.\n",
        "2. you can do both detection and descriptor computation at the same time using detectAndCompute()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Y_rsowhSq_"
      },
      "source": [
        "#compute descriptors\n",
        "\n",
        "keypoints, desc = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwD2a2A-gwuC"
      },
      "source": [
        "#@title Solution\n",
        "\n",
        "keypoints, desc = sift_detector.compute(image, keypoints)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnvmLamzhhmG"
      },
      "source": [
        "print(type(desc))\n",
        "print(desc.shape)\n",
        "print(desc.dtype)\n",
        "print(desc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r58XcTLHrLTl"
      },
      "source": [
        "#Practice 4: keypoint matching\n",
        "\n",
        "1. read 2 images box.png, box_in_scene.png in grayscale\n",
        "2. detect keypoints and compute descriptors for both images\n",
        "3. instantiate a brute force matcher object using cv2.BFMatcher(matching metric) for the matching metric you can use cv2.NORM_L2\n",
        "4. use the knnMatch of the bruteforce matcher object to find matches in the second image for each keypoint of the first image using the function knnMatch(descriptors1, descriptors2, k). use k = 2\n",
        "\n",
        "5. use lowe's ration to extract good matches. set the threshold to 0.75\n",
        "6. draw matches using the function cv2.drawMatches(image1, keypoints1, image2, keypoints2, matches, section). section is again None.\n",
        "7. show the matches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl6UGHtHtYL2"
      },
      "source": [
        "#read images\n",
        "image1 = ...\n",
        "image2 = ...\n",
        "\n",
        "#detect keypoints and extract descriptors\n",
        "kp1, desc1 = ...\n",
        "kp2, desc2 = ...\n",
        "\n",
        "#matcher class\n",
        "bf_matcher = ...\n",
        "\n",
        "#knn matching \n",
        "matches = ...\n",
        "\n",
        "#finding good matches\n",
        "good_matches = []\n",
        "...\n",
        "\n",
        "print('%d good matches'%len(good_matches))\n",
        "\n",
        "#draw matches\n",
        "image_matches = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "EShM3xaYn8a1"
      },
      "source": [
        "#@title Solution\n",
        "\n",
        "#read images\n",
        "image1 = cv2.imread('images/box.png', cv2.IMREAD_GRAYSCALE)\n",
        "image2 = cv2.imread('images/box_in_scene.png', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "#detect keypoints and extract descriptors\n",
        "kp1, desc1 = sift_detector.detectAndCompute(image1, None)\n",
        "kp2, desc2 = sift_detector.detectAndCompute(image2, None)\n",
        "\n",
        "#matcher class\n",
        "bf_matcher = cv2.BFMatcher(cv2.NORM_L2)\n",
        "\n",
        "#knn matching \n",
        "matches = bf_matcher.knnMatch(desc1, desc2, 2)\n",
        "\n",
        "#finding good matches\n",
        "good_matches = []\n",
        "\n",
        "for m in matches:\n",
        "  if m[0].distance / m[1].distance < 0.75:\n",
        "    good_matches.append(m[0])\n",
        "\n",
        "print('%d good matches'%len(good_matches))\n",
        "\n",
        "#draw matches\n",
        "image_matches = cv2.drawMatches(image1, kp1, image2, kp2, good_matches, None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw1Xf71psq55"
      },
      "source": [
        "#@title Run this cell to see results\n",
        "fig, axes = plt.subplots(1, 3, figsize = (30, 30))\n",
        "\n",
        "axes[0].imshow(image1, cmap = 'gray')\n",
        "axes[0].set_title('Image 1')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(image2, cmap = 'gray')\n",
        "axes[1].set_title('Image 2')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(image_matches, cmap = 'gray')\n",
        "axes[2].set_title('matches')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqvJuTOxuooU"
      },
      "source": [
        "#Practice 5: matching using Hellinger distance\n",
        "\n",
        "1. read 2 images box.png, box_in_scene.png in grayscale\n",
        "2. detect keypoints and compute descriptors for both images\n",
        "3. Normalize the descriptors so that $|d_i| = 1$.\n",
        "4. compute the Hellinger distance matrix $A_{nm}$ in which $a_{ij} = \\sqrt{1 - \\sqrt{d_i.d_j}}$ \n",
        "5. use lowe's ratio to find good matches. you can make match objects using cv2.DMatch(queryIdx, trainIdx, imgIdx, distance)\n",
        "6. draw matches using the function cv2.drawMatches(image1, keypoints1, image2, keypoints2, matches, section). section is again None.\n",
        "7. show the matches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK-gfkl0za5v"
      },
      "source": [
        "#Normalize descriptors\n",
        "desc1_N= ...\n",
        "desc2_N = ...\n",
        "\n",
        "#compute the distance matrix\n",
        "D_hell = ...\n",
        "\n",
        "#finding good matches\n",
        "good_matches = []\n",
        "...\n",
        "\n",
        "print('%d good matches'%len(good_matches))\n",
        "\n",
        "#draw matches\n",
        "image_matches = ...\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "TYmQ-cxfv3BZ"
      },
      "source": [
        "#@title Solution\n",
        "\n",
        "desc1_N = desc1 / np.linalg.norm(desc1, axis = 1, keepdims=True)\n",
        "desc2_N = desc2 / np.linalg.norm(desc2, axis = 1, keepdims=True)\n",
        "\n",
        "D_hell = np.sqrt(1 - np.sqrt(desc1_N @ desc2_N.T))\n",
        "\n",
        "good_matches = []\n",
        "for i in range(desc1_N.shape[0]):\n",
        "  sorted_idx = np.argsort(D_hell[i])\n",
        "  d1 = D_hell[i][sorted_idx[0]]\n",
        "  d2 = D_hell[i][sorted_idx[1]]\n",
        "\n",
        "  if d1 / d2 < 0.75:\n",
        "    match = cv2.DMatch(i, sorted_idx[0],0, d1)\n",
        "    good_matches.append(match)\n",
        "  \n",
        "\n",
        "image_matches = cv2.drawMatches(image1, kp1, image2, kp2, good_matches, None)\n"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "zVn06CyJyasC"
      },
      "source": [
        "#@title Run this cell to see results\n",
        "fig, axes = plt.subplots(1, 3, figsize = (30, 30))\n",
        "\n",
        "axes[0].imshow(image1, cmap = 'gray')\n",
        "axes[0].set_title('Image 1')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(image2, cmap = 'gray')\n",
        "axes[1].set_title('Image 2')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(image_matches, cmap = 'gray')\n",
        "axes[2].set_title('matches')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}